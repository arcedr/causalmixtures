df_tv$tstop <- rep(NA, dim(df_tv)[1])
for(i in unique(df_tv[,'id_unique'])){
flag <- 0
id_iter <- which(df_tv[,'id_unique']==i)
for(j in id_iter[-length(id_iter)]){
df_tv[j,'tstop'] <- df_tv[j+1,unlist(strsplit(time_points, "_"))[1]] - df_tv[j,unlist(strsplit(time_points, "_"))[1]] - flag
flag <- 0
if(df_tv[j,'tstop']==0){
flag <- 1
df_tv[j,'tstop'] <- 1
}}
if (NL==NM & i %in% ids_death_last){
df_tv[id_iter[length(id_iter)],'tstop'] <- 1
} else if (i %in% ids){
df_tv[id_iter[length(id_iter)],'tstop'] <- 21 - df_tv[id_iter[length(id_iter)],unlist(strsplit(time_points, "_"))[1]]
} else {
df_tv[id_iter[length(id_iter)],'tstop'] <- 1
}}
# Expand rows for person-time format
df_surv <- expandRows(df_tv, "tstop", drop=F)
df_surv$time <- sequence(rle(df_surv[,'id_unique'])$lengths)
df_surv$time2 <- df_surv$time^2
df_pred.data.astar.a.astar.a.y <- df_surv[,c(row.names(coef(Y))[-1],'id_unique')]
# Prediction
predict <- predict_surv_enet(df_pred.data.astar.a.astar.a.y, Y, id='id_unique')
PredictY_IEMIED <- mean(predict[which(predict[,'time']==t),'surv_prob'])
###################################
# pred.data.astar.a.y
ids_death_last <- pred.data.astar.a.y[which(PredictL_a[,NL]==1),'id_unique']
df_tv <- reshape(as.data.frame(pred.data.astar.a.y), direction = "long", varying = vector_time_points,
sep = "_", times=as.character(seq(1,length(time_points))), idvar='id_unique')
df_tv <- df_tv[order(df_tv$id_unique),]
df_tv <- df_tv[!is.na(df_tv[,unlist(strsplit(m[1], "_"))[1]]),]
ids <- as.numeric(names(table(df_tv[,'id_unique'])[which(table(df_tv[,'id_unique'])==length(time_points))]))
df_tv$tstop <- rep(NA, dim(df_tv)[1])
for(i in unique(df_tv[,'id_unique'])){
flag <- 0
id_iter <- which(df_tv[,'id_unique']==i)
for(j in id_iter[-length(id_iter)]){
df_tv[j,'tstop'] <- df_tv[j+1,unlist(strsplit(time_points, "_"))[1]] - df_tv[j,unlist(strsplit(time_points, "_"))[1]] - flag
flag <- 0
if(df_tv[j,'tstop']==0){
flag <- 1
df_tv[j,'tstop'] <- 1
}}
if (NL==NM & i %in% ids_death_last){
df_tv[id_iter[length(id_iter)],'tstop'] <- 1
} else if (i %in% ids){
df_tv[id_iter[length(id_iter)],'tstop'] <- 21 - df_tv[id_iter[length(id_iter)],unlist(strsplit(time_points, "_"))[1]]
} else {
df_tv[id_iter[length(id_iter)],'tstop'] <- 1
}}
# Expand rows for person-time format
df_surv <- expandRows(df_tv, "tstop", drop=F)
df_surv$time <- sequence(rle(df_surv[,'id_unique'])$lengths)
df_surv$time2 <- df_surv$time^2
df_pred.data.astar.a.y <- df_surv[,c(row.names(coef(Y))[-1],'id_unique')]
# Prediction
predict <- predict_surv_enet(df_pred.data.astar.a.y, Y, id='id_unique')
PredictY_DEIEM <- mean(predict[which(predict[,'time']==t),'surv_prob'])
####################################
DE <- PredictY_DEIEM - PredictY_TEDE
IEM <- PredictY_IEDTE - PredictY_IEMIED
IED <- PredictY_IEMIED - PredictY_DEIEM
TE <- PredictY_IEDTE - PredictY_TEDE
effects <- cbind(DE, IEM, IED, TE)
return(effects)
}
# Bootstrap
start_time <- Sys.time()
boot <- foreach(i=1:5, .combine='rbind') %dopar% {
ind <- sample(1:dim(dat_dummy)[1], replace=TRUE)
data_boot <- dat_dummy[ind,]
data_boot$id_unique <- 1:dim(dat_dummy)[1]
# Split sampling
foldid_bi <- sample(1:2, size = dim(data_boot)[1], replace = TRUE)
dat_dum <- data_boot[foldid_bi==1,]
dat_dum_2 <- data_boot[foldid_bi==2,]
### M1 ###
# Perform 10-fold cross validation
# Divide all observations into 10 folds
foldid <- sample(1:10, size = dim(dat_dum)[1], replace = TRUE)
# Run model, cross validate over values for alpha and lambda
M1 <- cv.glmnet(x = data.matrix(dat_dum[,c("A1", "A2", "A3", "A4", "A5", "A6", "C")]),
y = dat_dum$M_1, family = "gaussian", nfolds = 10, foldid = foldid, alpha=0)
L1 <- cv.glmnet(x = data.matrix(dat_dum[,c("A1", "A2", "A3", "A4", "A5", "A6", "M_1", "C")]),
y = dat_dum$D1, family = "binomial", nfolds = 10, foldid = foldid, alpha=0)
foldid <- sample(1:10, size = dim(dat_dum[!is.na(dat_dum$M_2),])[1], replace = TRUE)
M2 <- cv.glmnet(x = data.matrix(dat_dum[!is.na(dat_dum$M_2),c("A1", "A2", "A3", "A4", "A5", "A6", "M_1", "C")]),
y = dat_dum[!is.na(dat_dum$M_2),'M_2'], family = "gaussian", nfolds = 10, foldid = foldid, alpha=0)
L2 <- cv.glmnet(x = data.matrix(dat_dum[!is.na(dat_dum$M_2),c("A1", "A2", "A3", "A4", "A5", "A6", "M_2", "C")]),
y = dat_dum[!is.na(dat_dum$M_2),'D2'], family = "binomial", nfolds = 10, foldid = foldid, alpha=0)
# Data augmentation method for counting process format for the outcome model
df <- tmerge(dat_dum, dat_dum, id=id_unique, endpt=event(time_to_event, event))
df_tv <- reshape(dat_dum, direction = "long", varying = c("M_1", "time.since.first.exam_1", "M_2", "time.since.first.exam_2"),
sep = "_", times=c('1','2'), idvar='id_unique')
df_tv <- df_tv[order(df_tv$id_unique),]
df <- tmerge(df, df_tv, id=id_unique, M=tdc(time.since.first.exam,M))
df$timediff <- df$tstop - df$tstart
df_surv <- expandRows(df, "timediff", drop=F)
df_surv$time <- sequence(rle(df_surv$id_unique)$lengths)
df_surv$time2 <- df_surv$time^2
df_surv$case <- ifelse(df_surv$time==df_surv$time_to_event &
df_surv$event==1, 1, 0)
df_surv$tstop <- df_surv$time + 1
foldid <- sample(1:10, size = dim(df_surv)[1], replace = TRUE)
Y <- cv.glmnet(x = data.matrix(df_surv[,c("A1", "A2", "A3", "A4", "A5", "A6", "M", "C","time", "time2")]),
y = df_surv$case, family = "binomial", nfolds = 10, foldid = foldid, alpha=0, parallel=TRUE)
# Mediation function parameters specification
treat <- c("A1", "A2", "A3", "A4", "A5", "A6")
L = list(L1=L1, L2=L2)
m <- c('M_1', 'M_2')
M = list(M1=M1, M2=M2)
time_points <- c("time.since.first.exam_1", "time.since.first.exam_2")
data <- dat_dum_2
a <- t(matrix(rep(apply(data[,treat], 2, quantile, 0.1), dim(data)[1]), nrow=length(treat), ncol=dim(data)[1]))
a_star <- t(matrix(rep(apply(data[,treat], 2, quantile, 0.9), dim(data)[1]), nrow=length(treat), ncol=dim(data)[1]))
control.value=a
treat.value=a_star
# Mediational g formula call
mesa_mediation <- med_enet_bin(L=L, M, m, Y, treat=treat, control.value=a, treat.value=a_star, data, time_points, t=20)
mesa_mediation
}
table(dat_dummy$D1)
table(dat_dummy$D2)
table(dat_dummy$event)
dat_dummy <- Mixture_Dat_Sim_Survival(n = 5000, M = 6,
sigsq.true = 0.1)
dat_dummy$time.since.first.exam_1 <- rep(0, times=dim(dat_dummy)[1])
dat_dummy$time.since.first.exam_2 <- rep(5, times=dim(dat_dummy)[1])
dat_dummy$time_to_event <- ceiling(dat_dummy$time_to_event)
table(dat_dummy$D1)
table(dat_dummy$D2)
table(dat_dummy$event)
summary(dat_dummy$time_to_event)
# Bootstrap
start_time <- Sys.time()
boot <- foreach(i=1:5, .combine='rbind') %dopar% {
ind <- sample(1:dim(dat_dummy)[1], replace=TRUE)
data_boot <- dat_dummy[ind,]
data_boot$id_unique <- 1:dim(dat_dummy)[1]
# Split sampling
foldid_bi <- sample(1:2, size = dim(data_boot)[1], replace = TRUE)
dat_dum <- data_boot[foldid_bi==1,]
dat_dum_2 <- data_boot[foldid_bi==2,]
### M1 ###
# Perform 10-fold cross validation
# Divide all observations into 10 folds
foldid <- sample(1:10, size = dim(dat_dum)[1], replace = TRUE)
# Run model, cross validate over values for alpha and lambda
M1 <- cv.glmnet(x = data.matrix(dat_dum[,c("A1", "A2", "A3", "A4", "A5", "A6", "C")]),
y = dat_dum$M_1, family = "gaussian", nfolds = 10, foldid = foldid, alpha=0)
L1 <- cv.glmnet(x = data.matrix(dat_dum[,c("A1", "A2", "A3", "A4", "A5", "A6", "M_1", "C")]),
y = dat_dum$D1, family = "binomial", nfolds = 10, foldid = foldid, alpha=0)
foldid <- sample(1:10, size = dim(dat_dum[!is.na(dat_dum$M_2),])[1], replace = TRUE)
M2 <- cv.glmnet(x = data.matrix(dat_dum[!is.na(dat_dum$M_2),c("A1", "A2", "A3", "A4", "A5", "A6", "M_1", "C")]),
y = dat_dum[!is.na(dat_dum$M_2),'M_2'], family = "gaussian", nfolds = 10, foldid = foldid, alpha=0)
L2 <- cv.glmnet(x = data.matrix(dat_dum[!is.na(dat_dum$M_2),c("A1", "A2", "A3", "A4", "A5", "A6", "M_2", "C")]),
y = dat_dum[!is.na(dat_dum$M_2),'D2'], family = "binomial", nfolds = 10, foldid = foldid, alpha=0)
# Data augmentation method for counting process format for the outcome model
df <- tmerge(dat_dum, dat_dum, id=id_unique, endpt=event(time_to_event, event))
df_tv <- reshape(dat_dum, direction = "long", varying = c("M_1", "time.since.first.exam_1", "M_2", "time.since.first.exam_2"),
sep = "_", times=c('1','2'), idvar='id_unique')
df_tv <- df_tv[order(df_tv$id_unique),]
df <- tmerge(df, df_tv, id=id_unique, M=tdc(time.since.first.exam,M))
df$timediff <- df$tstop - df$tstart
df_surv <- expandRows(df, "timediff", drop=F)
df_surv$time <- sequence(rle(df_surv$id_unique)$lengths)
df_surv$time2 <- df_surv$time^2
df_surv$case <- ifelse(df_surv$time==df_surv$time_to_event &
df_surv$event==1, 1, 0)
df_surv$tstop <- df_surv$time + 1
foldid <- sample(1:10, size = dim(df_surv)[1], replace = TRUE)
Y <- cv.glmnet(x = data.matrix(df_surv[,c("A1", "A2", "A3", "A4", "A5", "A6", "M", "C","time", "time2")]),
y = df_surv$case, family = "binomial", nfolds = 10, foldid = foldid, alpha=0, parallel=TRUE)
# Mediation function parameters specification
treat <- c("A1", "A2", "A3", "A4", "A5", "A6")
L = list(L1=L1, L2=L2)
m <- c('M_1', 'M_2')
M = list(M1=M1, M2=M2)
time_points <- c("time.since.first.exam_1", "time.since.first.exam_2")
data <- dat_dum_2
a <- t(matrix(rep(apply(data[,treat], 2, quantile, 0.1), dim(data)[1]), nrow=length(treat), ncol=dim(data)[1]))
a_star <- t(matrix(rep(apply(data[,treat], 2, quantile, 0.9), dim(data)[1]), nrow=length(treat), ncol=dim(data)[1]))
control.value=a
treat.value=a_star
# Mediational g formula call
mesa_mediation <- med_enet_bin(L=L, M, m, Y, treat=treat, control.value=a, treat.value=a_star, data, time_points, t=20)
mesa_mediation
}
summary(dat_dummy$time_to_event)
CorrMatrix <- diag(1, 6)
CorrMatrix[lower.tri(CorrMatrix)] <- 0.1
CorrMatrix <- CorrMatrix + t(CorrMatrix) - diag(1, 6)
CorrMatrix_pd <- nearPD(CorrMatrix)$mat
# Simulate covariate value
C = rbinom(n, 1, 0.4)
# Simulate from multivariate normal with mean and correlation matrix
eps_Z <- MASS::mvrnorm(n = n, mu = rep(0, 6), Sigma = as.matrix(CorrMatrix_pd))
mu_Z1 <- mapply(FUN=HFun_z1, C=C)
Z1 <- mu_Z1 + Z[,1]
mu_Z2 <- mapply(FUN=HFun_z2, C=C)
Z2 <- mu_Z2 + Z[,2]
mu_Z3 <- mapply(FUN=HFun_z3, C=C)
Z3 <- mu_Z3 + Z[,3]
mu_Z4 <- mapply(FUN=HFun_z4, C=C)
Z4 <- mu_Z4 + Z[,4]
mu_Z5 <- mapply(FUN=HFun_z5, C=C)
Z5 <- mu_Z5 + Z[,5]
mu_Z6 <- mapply(FUN=HFun_z6, C=C)
Z6 <- mu_Z6 + Z[,6]
Z <- cbind(Z1,Z2,Z3,Z4,Z5,Z6)
colnames(Z) <- paste0("A", 1:M)
# Simulate error
# Where do we get sigsq.true from?
eps_M1 <- rnorm(n, sd = sqrt(sigsq.true))
mu_M1 <- mapply(FUN=HFun_M1, z=split(Z, row(Z)), C=C)
M1 <- drop(mu_M1 + eps_M1)
eps_M2 <- rnorm(n, sd = sqrt(sigsq.true))
mu_M2 <- mapply(FUN=HFun_M2, z=split(Z, row(Z)), M1=M1, C=C)
M2 <- drop(mu_M2 + eps_M2)
eps_Y <- rnorm(n, sd = sqrt(sigsq.true))
mu <- mapply(FUN=HFun_Y_M1, z=split(Z, row(Z)), M1=M1, C=C)
y <- drop(mu + eps_Y)
# y[y <= 0] <- .Machine$double.eps # Replace non-positives with a tiny positive
eps_D <- rnorm(n, sd = sqrt(sigsq.true))
mu_D <- mapply(FUN=HFun_D_M1, z=split(Z, row(Z)), M1=M1, C=C)
D <- drop(mu_D + eps_D)
# D[D <= 0] <- .Machine$double.eps # Replace non-positives with a tiny positive
t_y <- rweibull(n, 1, exp(-y)*100)
t_d <- rweibull(n, 1, exp(-D)*100)
summary(t_y)
summary(t_d)
t_y <- rweibull(n, 1, exp(-y)*50)
t_d <- rweibull(n, 1, exp(-D)*50)
summary(t_y)
summary(t_d)
t_y <- rweibull(n, 1, exp(-y)*20)
t_d <- rweibull(n, 1, exp(-D)*20)
summary(t_y)
summary(t_d)
t_2 = 20
t_3 = 30
HFun_z1 <- function(C) 0.2*C
HFun_z2 <- function(C) 0.4*C
HFun_z3 <- function(C) 0.5*C
HFun_z4 <- function(C) 0.1*C
HFun_z5 <- function(C) C
HFun_z6 <- function(C) 0.35*C
HFun_M1 <- function(z, C) 0.5*(z[1] + 0.5*z[3] + 0.6*z[4] + 0.7*z[5] + 0.2*z[6] + 0.4*C)
HFun_M2 <- function(z, M1, C) 0.5*(z[1] + 0.4*z[2] + 0.1*z[4]  + 0.1*z[3] + z[5] + 0.8*z[6]) + 0.8*M1 + 0.8*C
HFun_Y_M1 <- function(z, M1, C) 0.2*(0.7*z[1] + 0.7*z[3] + 0.7*z[4] + M1 + 0.5*C)
HFun_Y_M1_M2 <- function(z, M1, M2, C) 0.2*(0.8*z[1] + 0.7*z[4] + z[5]
+ 0.8*M1 + 0.5*M2 + 0.6*C)
HFun_D_M1 <- function(z, M1, C) 0.3*(0.3*z[1] + 0.4*z[3] + 0.2*z[5] + 1.2*M1 + 0.6*C)
HFun_D_M2 <- function(z, M2, C) 0.3*(0.3*z[1] + 0.4*z[5] + 0.2*z[2] + 0.6*M2 + 0.3*C)
Mixture_Dat_Sim_Survival <- function(n = 5000,
M = 6,
sigsq.true = 0.1){
CorrMatrix <- diag(1, 6)
CorrMatrix[lower.tri(CorrMatrix)] <- 0.1
CorrMatrix <- CorrMatrix + t(CorrMatrix) - diag(1, 6)
CorrMatrix_pd <- nearPD(CorrMatrix)$mat
# Simulate covariate value
C = rbinom(n, 1, 0.4)
# Simulate from multivariate normal with mean and correlation matrix
eps_Z <- MASS::mvrnorm(n = n, mu = rep(0, 6), Sigma = as.matrix(CorrMatrix_pd))
mu_Z1 <- mapply(FUN=HFun_z1, C=C)
Z1 <- mu_Z1 + Z[,1]
mu_Z2 <- mapply(FUN=HFun_z2, C=C)
Z2 <- mu_Z2 + Z[,2]
mu_Z3 <- mapply(FUN=HFun_z3, C=C)
Z3 <- mu_Z3 + Z[,3]
mu_Z4 <- mapply(FUN=HFun_z4, C=C)
Z4 <- mu_Z4 + Z[,4]
mu_Z5 <- mapply(FUN=HFun_z5, C=C)
Z5 <- mu_Z5 + Z[,5]
mu_Z6 <- mapply(FUN=HFun_z6, C=C)
Z6 <- mu_Z6 + Z[,6]
Z <- cbind(Z1,Z2,Z3,Z4,Z5,Z6)
colnames(Z) <- paste0("A", 1:M)
# Simulate error
# Where do we get sigsq.true from?
eps_M1 <- rnorm(n, sd = sqrt(sigsq.true))
mu_M1 <- mapply(FUN=HFun_M1, z=split(Z, row(Z)), C=C)
M1 <- drop(mu_M1 + eps_M1)
eps_M2 <- rnorm(n, sd = sqrt(sigsq.true))
mu_M2 <- mapply(FUN=HFun_M2, z=split(Z, row(Z)), M1=M1, C=C)
M2 <- drop(mu_M2 + eps_M2)
eps_Y <- rnorm(n, sd = sqrt(sigsq.true))
mu <- mapply(FUN=HFun_Y_M1, z=split(Z, row(Z)), M1=M1, C=C)
y <- drop(mu + eps_Y)
# y[y <= 0] <- .Machine$double.eps # Replace non-positives with a tiny positive
eps_D <- rnorm(n, sd = sqrt(sigsq.true))
mu_D <- mapply(FUN=HFun_D_M1, z=split(Z, row(Z)), M1=M1, C=C)
D <- drop(mu_D + eps_D)
# D[D <= 0] <- .Machine$double.eps # Replace non-positives with a tiny positive
t_y <- rweibull(n, 1, exp(-y)*20)
t_d <- rweibull(n, 1, exp(-D)*20)
summary(t_y)
summary(t_d)
dtSurv <- data.frame(cbind(Z, M_1=M1, M_2=M2, C, t_y, t_d))
dtSurv$id <- seq(1:dim(dtSurv)[1])
dtSurv$time_to_event <- rep(NA, dim(dtSurv)[1])
# Parallel foreach loop to update survival times taking M2 into account
for (i in 1:length(dtSurv$id)){
print(i)
if (dtSurv$t_d[i] > t_2) {
dtSurv$t_d[i] <- 0
while (dtSurv$t_d[i] < t_2) {
mu_D <- HFun_D_M2(z=as.vector(unlist(dtSurv[i,1:dim(Z)[2]])), M2=dtSurv$M_2[i], C=C[i])
D <- (mu_D + eps_D[i])
dtSurv$t_d[i] <- rweibull(1, 1, exp(-D)*20)
}
}
if (dtSurv$t_y[i] > t_2) {
dtSurv$t_y[i] <- 0
while (dtSurv$t_y[i] < t_2) {
mu_Y <- HFun_Y_M1_M2(z=as.vector(unlist(dtSurv[i,1:dim(Z)[2]])), M1=dtSurv$M_1[i], M2=dtSurv$M_2[i], C=C[i])
Y <- (mu_Y + eps_Y[i])
dtSurv$t_y[i] <- rweibull(1, 1, exp(-y)*20)
}
}
if (dtSurv$t_y[i]<=t_2 | dtSurv$t_d[i]<=t_2){
dtSurv$M_2[i] <- NA
}
dtSurv$time_to_event[i] = pmin(dtSurv$t_y[i], dtSurv$t_d[i])
dtSurv$event = ifelse(dtSurv$t_y < dtSurv$t_d, 1, 0)
}
# Define death indicator
dtSurv$D1 = ifelse((dtSurv$t_d <= t_2) & (dtSurv$t_d <= dtSurv$t_y), 1, 0)
dtSurv$D2 = ifelse((dtSurv$D1 == 1) | ((dtSurv$t_d <= t_3) & (dtSurv$t_d <= dtSurv$t_y)) , 1, 0)
dtSurv$nci = ifelse((dtSurv$D1 == 1) | (dtSurv$D2 == 1) , 1, 0)
dtSurv$event[dtSurv$time_to_event > t_3] = 0
dtSurv$time_to_event[dtSurv$time_to_event > t_3] = t_3
dtSurv$D1 = as.factor(dtSurv$D1)
dtSurv$D2 = as.factor(dtSurv$D2)
dtSurv$event = as.factor(dtSurv$event)
return(dtSurv)
}
dat_dummy <- Mixture_Dat_Sim_Survival(n = 5000, M = 6,
sigsq.true = 0.1)
dat_dummy$time.since.first.exam_1 <- rep(0, times=dim(dat_dummy)[1])
dat_dummy$time.since.first.exam_2 <- rep(5, times=dim(dat_dummy)[1])
dat_dummy$time_to_event <- ceiling(dat_dummy$time_to_event)
table(dat_dummy$D1)
table(dat_dummy$D2)
table(dat_dummy$event)
summary(dat_dummy$time_to_event)
# Bootstrap
start_time <- Sys.time()
boot <- foreach(i=1:5, .combine='rbind') %dopar% {
ind <- sample(1:dim(dat_dummy)[1], replace=TRUE)
data_boot <- dat_dummy[ind,]
data_boot$id_unique <- 1:dim(dat_dummy)[1]
# Split sampling
foldid_bi <- sample(1:2, size = dim(data_boot)[1], replace = TRUE)
dat_dum <- data_boot[foldid_bi==1,]
dat_dum_2 <- data_boot[foldid_bi==2,]
### M1 ###
# Perform 10-fold cross validation
# Divide all observations into 10 folds
foldid <- sample(1:10, size = dim(dat_dum)[1], replace = TRUE)
# Run model, cross validate over values for alpha and lambda
M1 <- cv.glmnet(x = data.matrix(dat_dum[,c("A1", "A2", "A3", "A4", "A5", "A6", "C")]),
y = dat_dum$M_1, family = "gaussian", nfolds = 10, foldid = foldid, alpha=0)
L1 <- cv.glmnet(x = data.matrix(dat_dum[,c("A1", "A2", "A3", "A4", "A5", "A6", "M_1", "C")]),
y = dat_dum$D1, family = "binomial", nfolds = 10, foldid = foldid, alpha=0)
foldid <- sample(1:10, size = dim(dat_dum[!is.na(dat_dum$M_2),])[1], replace = TRUE)
M2 <- cv.glmnet(x = data.matrix(dat_dum[!is.na(dat_dum$M_2),c("A1", "A2", "A3", "A4", "A5", "A6", "M_1", "C")]),
y = dat_dum[!is.na(dat_dum$M_2),'M_2'], family = "gaussian", nfolds = 10, foldid = foldid, alpha=0)
L2 <- cv.glmnet(x = data.matrix(dat_dum[!is.na(dat_dum$M_2),c("A1", "A2", "A3", "A4", "A5", "A6", "M_2", "C")]),
y = dat_dum[!is.na(dat_dum$M_2),'D2'], family = "binomial", nfolds = 10, foldid = foldid, alpha=0)
# Data augmentation method for counting process format for the outcome model
df <- tmerge(dat_dum, dat_dum, id=id_unique, endpt=event(time_to_event, event))
df_tv <- reshape(dat_dum, direction = "long", varying = c("M_1", "time.since.first.exam_1", "M_2", "time.since.first.exam_2"),
sep = "_", times=c('1','2'), idvar='id_unique')
df_tv <- df_tv[order(df_tv$id_unique),]
df <- tmerge(df, df_tv, id=id_unique, M=tdc(time.since.first.exam,M))
df$timediff <- df$tstop - df$tstart
df_surv <- expandRows(df, "timediff", drop=F)
df_surv$time <- sequence(rle(df_surv$id_unique)$lengths)
df_surv$time2 <- df_surv$time^2
df_surv$case <- ifelse(df_surv$time==df_surv$time_to_event &
df_surv$event==1, 1, 0)
df_surv$tstop <- df_surv$time + 1
foldid <- sample(1:10, size = dim(df_surv)[1], replace = TRUE)
Y <- cv.glmnet(x = data.matrix(df_surv[,c("A1", "A2", "A3", "A4", "A5", "A6", "M", "C","time", "time2")]),
y = df_surv$case, family = "binomial", nfolds = 10, foldid = foldid, alpha=0, parallel=TRUE)
# Mediation function parameters specification
treat <- c("A1", "A2", "A3", "A4", "A5", "A6")
L = list(L1=L1, L2=L2)
m <- c('M_1', 'M_2')
M = list(M1=M1, M2=M2)
time_points <- c("time.since.first.exam_1", "time.since.first.exam_2")
data <- dat_dum_2
a <- t(matrix(rep(apply(data[,treat], 2, quantile, 0.1), dim(data)[1]), nrow=length(treat), ncol=dim(data)[1]))
a_star <- t(matrix(rep(apply(data[,treat], 2, quantile, 0.9), dim(data)[1]), nrow=length(treat), ncol=dim(data)[1]))
control.value=a
treat.value=a_star
# Mediational g formula call
mesa_mediation <- med_enet_bin(L=L, M, m, Y, treat=treat, control.value=a, treat.value=a_star, data, time_points, t=20)
mesa_mediation
}
dat_dummy$time.since.first.exam_1 <- rep(0, times=dim(dat_dummy)[1])
dat_dummy$time.since.first.exam_2 <- rep(20, times=dim(dat_dummy)[1])
dat_dummy$time_to_event <- ceiling(dat_dummy$time_to_event)
table(dat_dummy$D1)
table(dat_dummy$D2)
table(dat_dummy$event)
summary(dat_dummy$time_to_event)
# Bootstrap
start_time <- Sys.time()
boot <- foreach(i=1:5, .combine='rbind') %dopar% {
ind <- sample(1:dim(dat_dummy)[1], replace=TRUE)
data_boot <- dat_dummy[ind,]
data_boot$id_unique <- 1:dim(dat_dummy)[1]
# Split sampling
foldid_bi <- sample(1:2, size = dim(data_boot)[1], replace = TRUE)
dat_dum <- data_boot[foldid_bi==1,]
dat_dum_2 <- data_boot[foldid_bi==2,]
### M1 ###
# Perform 10-fold cross validation
# Divide all observations into 10 folds
foldid <- sample(1:10, size = dim(dat_dum)[1], replace = TRUE)
# Run model, cross validate over values for alpha and lambda
M1 <- cv.glmnet(x = data.matrix(dat_dum[,c("A1", "A2", "A3", "A4", "A5", "A6", "C")]),
y = dat_dum$M_1, family = "gaussian", nfolds = 10, foldid = foldid, alpha=0)
L1 <- cv.glmnet(x = data.matrix(dat_dum[,c("A1", "A2", "A3", "A4", "A5", "A6", "M_1", "C")]),
y = dat_dum$D1, family = "binomial", nfolds = 10, foldid = foldid, alpha=0)
foldid <- sample(1:10, size = dim(dat_dum[!is.na(dat_dum$M_2),])[1], replace = TRUE)
M2 <- cv.glmnet(x = data.matrix(dat_dum[!is.na(dat_dum$M_2),c("A1", "A2", "A3", "A4", "A5", "A6", "M_1", "C")]),
y = dat_dum[!is.na(dat_dum$M_2),'M_2'], family = "gaussian", nfolds = 10, foldid = foldid, alpha=0)
L2 <- cv.glmnet(x = data.matrix(dat_dum[!is.na(dat_dum$M_2),c("A1", "A2", "A3", "A4", "A5", "A6", "M_2", "C")]),
y = dat_dum[!is.na(dat_dum$M_2),'D2'], family = "binomial", nfolds = 10, foldid = foldid, alpha=0)
# Data augmentation method for counting process format for the outcome model
df <- tmerge(dat_dum, dat_dum, id=id_unique, endpt=event(time_to_event, event))
df_tv <- reshape(dat_dum, direction = "long", varying = c("M_1", "time.since.first.exam_1", "M_2", "time.since.first.exam_2"),
sep = "_", times=c('1','2'), idvar='id_unique')
df_tv <- df_tv[order(df_tv$id_unique),]
df <- tmerge(df, df_tv, id=id_unique, M=tdc(time.since.first.exam,M))
df$timediff <- df$tstop - df$tstart
df_surv <- expandRows(df, "timediff", drop=F)
df_surv$time <- sequence(rle(df_surv$id_unique)$lengths)
df_surv$time2 <- df_surv$time^2
df_surv$case <- ifelse(df_surv$time==df_surv$time_to_event &
df_surv$event==1, 1, 0)
df_surv$tstop <- df_surv$time + 1
foldid <- sample(1:10, size = dim(df_surv)[1], replace = TRUE)
Y <- cv.glmnet(x = data.matrix(df_surv[,c("A1", "A2", "A3", "A4", "A5", "A6", "M", "C","time", "time2")]),
y = df_surv$case, family = "binomial", nfolds = 10, foldid = foldid, alpha=0, parallel=TRUE)
# Mediation function parameters specification
treat <- c("A1", "A2", "A3", "A4", "A5", "A6")
L = list(L1=L1, L2=L2)
m <- c('M_1', 'M_2')
M = list(M1=M1, M2=M2)
time_points <- c("time.since.first.exam_1", "time.since.first.exam_2")
data <- dat_dum_2
a <- t(matrix(rep(apply(data[,treat], 2, quantile, 0.1), dim(data)[1]), nrow=length(treat), ncol=dim(data)[1]))
a_star <- t(matrix(rep(apply(data[,treat], 2, quantile, 0.9), dim(data)[1]), nrow=length(treat), ncol=dim(data)[1]))
control.value=a
treat.value=a_star
# Mediational g formula call
mesa_mediation <- med_enet_bin(L=L, M, m, Y, treat=treat, control.value=a, treat.value=a_star, data, time_points, t=20)
mesa_mediation
}
end_time <- Sys.time()
time_taken <- end_time - start_time
print(time_taken)
# Calculate the effects
# Direct effect
DE <- quantile(boot[,1], 0.5)*100
DE_low <- quantile(boot[,1], 0.025)*100
DE_up <- quantile(boot[,1], 0.975)*100
DE_result <- paste0(round(DE,3), ' (', round(DE_low, 3), ', ', round(DE_up, 3), ')')
# Indirect effect through M
IEM <- quantile(boot[,2], 0.5)*100
IEM_low <- quantile(boot[,2], 0.025)*100
IEM_up <- quantile(boot[,2], 0.975)*100
IEM_result <- paste0(round(IEM,3), ' (', round(IEM_low, 3), ', ', round(IEM_up, 3), ')')
# Indirect effect through D
IED <- quantile(boot[,3], 0.5)*100
IED_low <- quantile(boot[,3], 0.025)*100
IED_up <- quantile(boot[,3], 0.975)*100
IED_result <- paste0(round(IED,3), ' (', round(IED_low, 3), ', ', round(IED_up, 3), ')')
# Total effect
TE <- quantile(boot[,4], 0.5)*100
TE_low <- quantile(boot[,4], 0.025)*100
TE_up <- quantile(boot[,4], 0.975)*100
TE_result <- paste0(round(TE,3), ' (', round(TE_low, 3), ', ', round(TE_up, 3), ')')
res <- list(DE=DE_result, IEM=IEM_result, IED=IED_result, TE=TE_result)
res
table(dat_dummy$D1)
table(dat_dummy$D2)
table(dat_dummy$event)
summary(dat_dummy$time_to_event)
t_y <- rweibull(n, 1, exp(-y)*20)
t_d <- rweibull(n, 1, exp(-D)*20)
summary(t_y)
summary(t_d)
t_y <- rweibull(n, 1, exp(-y))
t_d <- rweibull(n, 1, exp(-D))
summary(t_y)
summary(t_d)
t_y <- rweibull(n, 1, exp(-y)*50)
t_d <- rweibull(n, 1, exp(-D)*50)
summary(t_y)
summary(t_d)
setwd("/Users/ad3531/Documents/CausalMixtures/causalmixtures")
pkgdown::build_site()
devtools::document()
pkgdown::build_site()
